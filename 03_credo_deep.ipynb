{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder1 = autoencoder.layers[-3]\n",
    "decoder2 = autoencoder.layers[-2]\n",
    "decoder3 = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder3(decoder2(decoder1(encoded_input))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from credo import load_data\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = load_data(use_worms=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10912, 784)\n",
      "(496, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 2s 12ms/step - loss: 0.3495 - val_loss: 0.0874\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0726 - val_loss: 0.0661\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0606 - val_loss: 0.0561\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0524 - val_loss: 0.0497\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0483 - val_loss: 0.0472\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0468 - val_loss: 0.0466\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0463 - val_loss: 0.0460\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0458 - val_loss: 0.0456\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0454 - val_loss: 0.0453\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0448 - val_loss: 0.0439\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0431 - val_loss: 0.0427\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0416 - val_loss: 0.0399\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0370\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0366 - val_loss: 0.0357\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0356 - val_loss: 0.0350\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0346 - val_loss: 0.0341\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0337 - val_loss: 0.0333\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0330 - val_loss: 0.0328\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0325 - val_loss: 0.0324\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0320 - val_loss: 0.0319\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0317 - val_loss: 0.0317\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0314 - val_loss: 0.0316\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0311 - val_loss: 0.0313\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0309 - val_loss: 0.0311\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0307 - val_loss: 0.0310\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0308\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.0307\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0301 - val_loss: 0.0305\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0302\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.0301\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0294 - val_loss: 0.0300\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.0299\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0298\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0290 - val_loss: 0.0297\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0296\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0287 - val_loss: 0.0296\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0294\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0285 - val_loss: 0.0294\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0284 - val_loss: 0.0292\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0291\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0281 - val_loss: 0.0290\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0290\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0279 - val_loss: 0.0288\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0288\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0277 - val_loss: 0.0287\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0274 - val_loss: 0.0285\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0273 - val_loss: 0.0284\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0271 - val_loss: 0.0283\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0270 - val_loss: 0.0282\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0269 - val_loss: 0.0281\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0268 - val_loss: 0.0280\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.0279\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0265 - val_loss: 0.0280\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0278\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0278\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.0277\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0277\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0276\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0276\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0275\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0275\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0258 - val_loss: 0.0274\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0257 - val_loss: 0.0274\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0273\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0274\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0255 - val_loss: 0.0272\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0273\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0272\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.0271\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0252 - val_loss: 0.0272\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0252 - val_loss: 0.0271\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0251 - val_loss: 0.0272\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0251 - val_loss: 0.0271\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.0271\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.0270\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0270\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0270\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0269\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0248 - val_loss: 0.0269\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0269\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0269\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0246 - val_loss: 0.0269\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0246 - val_loss: 0.0269\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0246 - val_loss: 0.0268\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0245 - val_loss: 0.0270\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0245 - val_loss: 0.0269\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0245 - val_loss: 0.0269\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.0269\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.0269\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0243 - val_loss: 0.0269\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0243 - val_loss: 0.0269\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0243 - val_loss: 0.0269\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0242 - val_loss: 0.0268\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0242 - val_loss: 0.0269\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0242 - val_loss: 0.0269\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0242 - val_loss: 0.0269\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0241 - val_loss: 0.0269\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0241 - val_loss: 0.0269\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1af50cab7f0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2000x400 with 20 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiYAAAFECAYAAACjw4YIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiDUlEQVR4nO3deYxeddU48DvdKZ0u0NLSUihb2qBFCPzRRlAb01cwQoEERGkEFEUwoBVDwAqIJCwBlSUEIlipS0AD1FIQSMNiAVmEIhao0NpAK1NaShem63SZ31+/6L3nlpkO83zvzDOfz3/n5Mz0+76e3Ps8c7j3NLS2trZmAAAAAAAACfSq+gAAAAAAAEDPYTABAAAAAAAkYzABAAAAAAAkYzABAAAAAAAkYzABAAAAAAAkYzABAAAAAAAkYzABAAAAAAAkYzABAAAAAAAk06ejP7hr166sqakpa2xszBoaGjrzTHQzra2tWXNzczZ69OisV6/azbr0HP9L35Faqp7LMn3Hf7nWUQV9R2rusVTBtY4q6DtSc4+lCu3tuw4PJpqamrKxY8d29MepQytWrMgOOOCAmv1+PUcZfUdqte65LNN3RK51VEHfkZp7LFVwraMK+o7U3GOpQlt91+FRWWNjY0d/lDpV657Qc5TRd6SWoif0HUWudVRB35GaeyxVcK2jCvqO1NxjqUJbPdHhwYRHciiqdU/oOcroO1JL0RP6jiLXOqqg70jNPZYquNZRBX1Hau6xVKGtnrD8GgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASKZP1QcAAADoypYsWRJyAwcODLlZs2aF3BVXXFGTMwEAQHfmiQkAAAAAACAZgwkAAAAAACAZgwkAAAAAACAZgwkAAAAAACAZy68BAAA+xuDBg0Nuw4YNITdq1KgUxwEAgG7PExMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyll8DAAB8jJEjR4bcd7/73ZCbMGFCiuMAAEC354kJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGTsmAAAA9tCdd95Z9REAAKDb8sQEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQTJ+qDwAAAABA/XjzzTdD7sYbbwy53/zmNymOA9DlTJ06NeTmz59fwUmq44kJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGTsmAACoO+edd17I3X777bl44cKFoWby5Mk1OxMA9BRLly4NudNOOy3k7JgAeqpjjjkm5OyYAAAAAAAAqBGDCQAAAAAAIBmDCQAAAAAAIBmDCQAAAAAAIBnLrwGAbu2kk04KuXnz5lVwErqSu+++O+R++MMf5uJNmzalOg5Apc4888yQO/7440Pue9/7Xorj0AOMHTs25CZOnFjBSQDS++IXvxhyxWXXI0eODDVTpkwJuaeeeqrzDtbFeGICAAAAAABIxmACAAAAAABIxmACAAAAAABIxmACAAAAAABIxvJrAKBbmTZtWi6eMGFCqGltbQ25hx9+uGZnouv56le/GnJ9+/bNxatWrUp1HPhYzc3NIdfY2FjBSahXQ4cODbnRo0enPwg9xpIlS0Ju3Lhx6Q8CUIHi944sy7KzzjorF8+cOTPU1POi6zKemAAAAAAAAJIxmAAAAAAAAJIxmAAAAAAAAJIxmAAAAAAAAJKx/LpGvva1r+Xie++9t6KTAFTrnnvuCbmtW7eG3CuvvJKL+/SJt6idO3eG3K9+9auOH44ub8qUKSE3d+7cXNzS0hJqHn300Zqdie5h+PDhITdq1Khc3L9//1THgY9Vds+DzjRkyJCQ27BhQwUnoad48MEHQ27Hjh0VnASiF154IRcfcsghoWbZsmUhN2nSpJqdifoyZsyYkFu9enUufvjhh1Mdp8vyxAQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJBMt3qZadm73IrvhavCJZdcEnJnnHFGLi6+RyzLsuyJJ56o2Znovk455ZRcfMwxx4SazZs3h9x1111XqyPBbk2fPj0XX3jhhaFm6NChITdr1qyQu+uuuzrtXNSPO+64I+QmTJiQi+2ToMztt98ecieddFIuPvHEE0NN2We2Yh9eddVVn/B0kNerl/9ejNoaMWJEyJXtnYDO8otf/CLk5syZU8FJ6On++c9/htyRRx7Z5s9ddNFFtTgOPcT1118fcpdeemkFJ+nafAIGAAAAAACSMZgAAAAAAACSMZgAAAAAAACSMZgAAAAAAACS6VbLr7vCouspU6aE3E033RRyLS0tuXjbtm01OxPd16233hpyxcXpI0eODDUbNmwIuZNPPjkXT548+ROejp5swYIFIXf88ce3Wfe73/0u1JQtL4Yyp5xySsiNHz8+/UGoWyeccEIufuaZZ0LNcccdF3LDhg2r2Zkgy7KsX79+VR+BOjd06NCQ+8pXvpL+IPQYAwcODLkLL7ww5Hr37p2LFy1aFGpuv/32zjsYPc7EiRM79HO33XZbJ5+EnmT48OEht2bNmgpO0rV5YgIAAAAAAEjGYAIAAAAAAEjGYAIAAAAAAEjGYAIAAAAAAEimWy2/7gomTJgQck8//XTIbdy4MRc/++yztToS3djFF18ccvPnz2/z58oWYp966qm5uGxR00UXXbQHp6Mne/TRR0Nuy5YtIffYY4/lYouu+ST+/Oc/V30Eepjjjz++6iPQif7617+G3FFHHZWLFy5cGGqmTJlSqyNlWZZl69evz8WbN28ONTNmzKjpGeDggw8OubVr11ZwEnqKsoXry5cvD7lPfepTufj111+v1ZHooWbPnl31EeiBrr322pC75pprcvG8efNSHafL8sQEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQTI/YMXHuueeGXK9ecSbTntygQYNCzV/+8peQK75LFtqro++Ye++993JxcedElmXZ2WefHXLet9jzzJo1K+RGjRqVi7/85S+Hmuuuu65mZ4Ldef/990Nu7ty5uXjatGmpjgN0YZ///OdD7mc/+1kuPu6440LNzp07O/TvNTQ0hNyaNWtCbtWqVbl427Ztoebmm2/u0Blgd4rfR9etWxdqyvbWQS0deOCBVR+BHuicc84JuQsuuCAX25VIZ5s5c2bIjRs3Lv1BujhPTAAAAAAAAMkYTAAAAAAAAMkYTAAAAAAAAMkYTAAAAAAAAMn0iOXXZYuoJ0yYEHKDBw8Ouaamplx84403dtq5oDM9+uijubi1tTXUnH/++SFn+XXPc9ppp4XcH//4xwpOAm3bf//9Q27evHm5+Lbbbgs1F110Uc3OBHQfV155ZYd+btasWbn47LPPDjVly4T/8Ic/hNyMGTM6dAZor2K/ZlmW3X///RWcBKB7eP/996s+Aj3QWWedVfURuhxPTAAAAAAAAMkYTAAAAAAAAMkYTAAAAAAAAMkYTAAAAAAAAMn0iOXXc+bMCbnPfe5zIdfS0hJyL7zwQk3OBLX22GOPtStHfVu0aFHIvfjiiyHXu3fvFMeBTrHXXnvl4gMPPLCikwD16pvf/ObHxtCVbNiwIeR+8IMf5OKGhoZEpwHo+op/J7z11ltDzcUXX5zqONBjeWICAAAAAABIxmACAAAAAABIxmACAAAAAABIxmACAAAAAABIpkcsvy6zYMGCqo8AUHNDhw4NuWuvvTbk7r333gSngc6xadOmqo8AAF3GjBkzQu5LX/pSBScB6J7KFl1fccUVIXfNNdekOA70GJ6YAAAAAAAAkjGYAAAAAAAAkjGYAAAAAAAAkumxOyYA6s1DDz0Ucm+//XbI2SdBdzdt2rRcfN1111V0EgDomo444oiqjwDQrZXtk/j2t78dcnfddVeK40Bd8sQEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjOXXAN3Uueeem4ubm5tDzeLFi1MdBypz+eWXV30EAACgzll0DZ3LExMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyll8DdFODBw/OxWeddVZFJwEAAACA9vPEBAAAAAAAkIzBBAAAAAAAkIzBBAAAAAAAkIwdEwDd1C233FL1EQAAAABgj3liAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASKbDg4nW1tbOPAd1oNY9oecoo+9ILUVP6DuKXOuogr4jNfdYquBaRxX0Ham5x1KFtnqiw4OJ5ubmjv4odarWPaHnKKPvSC1FT+g7ilzrqIK+IzX3WKrgWkcV9B2pucdShbZ6oqG1g+OsXbt2ZU1NTVljY2PW0NDQocNRH1pbW7Pm5uZs9OjRWa9etXs7mJ7jf+k7UkvVc1mm7/gv1zqqoO9IzT2WKrjWUQV9R2rusVShvX3X4cEEAAAAAADAnrL8GgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASKZPR39w165dWVNTU9bY2Jg1NDR05pnoZlpbW7Pm5uZs9OjRWa9etZt16Tn+l74jtVQ9l2X6jv9yraMK+o7U3GOpgmsdVdB3pOYeSxXa23cdHkw0NTVlY8eO7eiPU4dWrFiRHXDAATX7/XqOMvqO1Grdc1mm74hc66iCviM191iq4FpHFfQdqbnHUoW2+q7Do7LGxsaO/ih1qtY9oecoo+9ILUVP6DuKXOuogr4jNfdYquBaRxX0Ham5x1KFtnqiw4MJj+RQVOue0HOU0XeklqIn9B1FrnVUQd+RmnssVXCtowr6jtTcY6lCWz1h+TUAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJCMwQQAAAAAAJBMn6oPAAAA0N307t075Hbu3Bly/fr1y8UtLS01OxMAAHQXnpgAAAAAAACSMZgAAAAAAACSMZgAAAAAAACSMZgAAAAAAACSsfwaAABgDw0YMKBddcOHD8/Fy5cvDzWtra2dciYAAOguPDEBAAAAAAAkYzABAAAAAAAkYzABAAAAAAAkY8cEAADAHtq0aVPIle2dWLt2bYrjAABAt+KJCQAAAAAAIBmDCQAAAAAAIBmDCQAAAAAAIBmDCQAAAAAAIBnLrwEA6JF69Yr/jc6uXbsqOAld3aBBg0Kuf//+Ibd58+aQ27p1ay5ubW3tvINBOzU0NIScXqSWhg0bFnI7duwIuebm5hTHAaAL8sQEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjOXXAADUnbLF1vvuu28u7tu3b6hZuXJlyFkQ2/MU++fEE08MNePHjw+53//+9yG3evXqXFy2/FWPUWtl18SdO3dWcBLqVe/evXPxjBkzQk3ZQuzLLrssF2/atKlzDwbQRfTpk/8zfP/+/UPNtm3bQq7ss2O98MQEAAAAAACQjMEEAAAAAACQjMEEAAAAAACQjB0TAADUnQMPPDDkHnvssVz84IMPhpqrrroq5LZv3955B6Nb2GeffXLxySefHGrWrFkTcqNGjQq5Dz/8MBcX38OeZfGdw1mWZVu3bm3znLA7DQ0NuXjEiBGhZt26dSFX9m5raI9Bgwbl4nPOOSfUDBgwIOTuvPPOXPzGG2906rkAqlD2eW/SpEm5eO3ataHm3XffDbmynVD1sp/MExMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyll8D0CUUlzQW4ywrX/BUL0ufaL9evdr+7yp27dqV4CR0FWXXiyOPPDLkxo8fn4s//elPh5qyRXWWX9e3sv/Nhw4dmotffvnlUPPII4+EXHHRdZbF/hkzZkyo6du3b8itXLkyF2/atCnUwO4U75WTJ08ONUuWLAm5N998Mxe7n9JexWtp2XWtbAn7XnvtVbMzwe4Ur5Ht/e5ZxnWSMocffnjIzZw5Mxf/4x//CDW33HJLyG3evLnTztXVeGICAAAAAABIxmACAAAAAABIxmACAAAAAABIxmACAAAAAABIxvLrPfRJFuIA9ER9+sRbzd577x1yxetr2YLjdevWdd7B6BbKFicWlyS2tLSEmrKcxXT1q+yz2MSJE0Nux44dbf5c2Wc96kfZ/7777bdfyBWXXz/wwAOh5oMPPgi5sp4q3s/Gjh0bak4//fSQu+OOO3Lxv/71r1ADu1PsxUMPPTTUjBw5MuQWL15cszNR37Zt25aLV61aFWqWLl0acm+99VbNzgRZlmUDBgwIucMOOywXF+/7WZZl69evD7mVK1eGXPE7qu8cPU+/fv1C7thjjw254vfYpqamULNly5aQq+e/O3tiAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMby6zb07t07F5ctcS1bclJccvfRRx+FmnpeXkLHlS38LSrrHf1EFYrXyP333z/U3HPPPSE3ZsyYkPvtb3+bi2+99dZQo8/rW9mi6+HDh4dcY2NjLl6+fHmosXSOZ599NuSKywnLlhAfdNBBIVdc1llcok33UfY5q7iwNcuy7NVXX23zd7X3OlNculnWY1/60pdCrnj9mz59eqhxX2R3iovehwwZEmqmTJkScg8++GAuXr16decejLpVvCa+8soroaa5uTnkXMfoTGV/szvqqKNC7qGHHsrFa9asCTVXXnllyJVdE4vXW3qesu+xZcuvN2zYkIsff/zxUFP29+N65okJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGTsm/kfZO2eL708vexfxZZddFnJvv/12Lv71r38datauXRty3q9Yv8reOzhq1KiQmzRpUi4+5JBDQs2iRYtCrvgOT/3FJ7HPPvuEXNn177jjjsvFZ555ZqgZN25cu/7N4juNt2zZ0q6fo36MGDEi5D772c+G3GuvvZaLt2/fXrMz0X298cYbIffiiy/m4hNPPDHUlH1m+/73v5+LX3/99VCzdevWPT0iFSjbC9Ged/nu3LmzXb+/7PNe8d/ctGlTqNlvv/1C7t///ne7/k0oU+y7jRs3hpqy7xnF77/QUWV/Xyn7PlH8Trxs2bJQY3cY7XXggQeG3BNPPBFyxf78+c9/HmoWLFgQcsUdAVnm7yyU75g455xzQu7555/PxWW7TXpaP3liAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASKZHLL8uW+BVtoipbFnd3nvvnYs/85nPhJpvfetbIfef//wnF7/00kuh5plnngm59i7Wo/sp68Mjjjgi5K6++upcPHHixFDz5JNPhtxTTz2Vi+fMmRNqFi9eHHIWiZFlcenmT3/601AzderUkGtpacnF7733XqiZMWNGyP3tb38LueLCdr3Z85QtXZ8+fXrIrV69OhcvXbq0Zmei+ypbJnfeeefl4p/85Cehpuyz3uTJk3PxkiVLQo3l191D2ULBHTt2hFzZ94L2KPu8t//+++fiQw89NNQsXLgw5G677bZc3NOWIfLJ9OvXLxcPHTo01JQtYvd9lM4ybty4kDv44INDrvj3lLvvvjvUlC3Edk0ky+Lf9soWrA8cODDk7rzzzlw8d+7cULN+/fqQ2759e8jpRco+/w0ZMiTkip8Jy/qpp/HEBAAAAAAAkIzBBAAAAAAAkIzBBAAAAAAAkIzBBAAAAAAAkEy3X35dtpiuT5/8/1mDBg0KNWULRsoWYhcXkxSXiGVZlt13330hV1x+/c4774Saji7Vo3sqWyT34osvhty5556bi8uW6AwYMCDkTj755Fw8c+bMUHPTTTeF3KuvvhpyljfVt759+4bcN77xjVx89NFHh5q///3vITd79uxc/Pzzz4eabdu2tSsHGzZsCLmye/ghhxySi8uWqVueTplVq1bl4ksuuSTUjB49OuSK/fTRRx917sGomeLn7fZ+/i5+Fir7ubLvDiNGjAi54neFDz74INR85zvfCbmyOihT1p9Tp07NxV/4whdCzeLFi0PO9Y2OKv6N5fLLLw81p556asgV/8Zy+OGHh5qmpqaQ27Jly54ekTpUvBeXfZ+4+OKLQ27hwoW5ePXq1aGm7PuEv5VQZuvWrSF3yy23hNzQoUNzcdnf9pqbmzvtXN2BJyYAAAAAAIBkDCYAAAAAAIBkDCYAAAAAAIBkuv2OibJ3uw4fPjwXjxkzJtQMGzYs5NatWxdyxfckLlmyJNTccMMNIbdixYpcvH79+lBTtnOA+lX2LsKNGzeGXPFdh2XvjC3LFd+7ecEFF4SaQw89NOQWLVoUcmU7WOieynaUTJkyJeQGDhyYi2+++eZQ89RTT4XcmjVrcrH3+vNJFPspy8rf93rCCSfk4rL9J2+88UbIeScsRS0tLSFXtheM7qHsnlfcPTdy5MhQU/Z+3+J3jIMPPjjUnHHGGSFX9v70xsbGXPzII4+EmnfffTfkoL2GDBkScj/+8Y9z8QEHHNBmTZaVvycb2mPHjh25uGyf4ssvvxxyxe+2ZZ/Xir8b/r/i39Xee++9UFP2XaF4by7ba9fevYjFM/jO0fOU3TvnzJkTcsUdKGV/h+5pPDEBAAAAAAAkYzABAAAAAAAkYzABAAAAAAAkYzABAAAAAAAk0+2XX5ctldmyZUsuLluEt++++4Zc2UKlt956KxeXLSsuW4hTXH5j0TXtVezp9i5OWrZsWS6eO3duqClb+l5c+pRlWbZ27dp2/Zt0LcVFnVlWvqxz1KhRIfenP/0pFy9fvjzUFK+tWWaxF52rbGnY/fffH3KXXXZZLj7//PNDzaWXXtqu36+HoX6Ufd4u5opLB7Msy5qbm0Nu2rRpufj//u//Qs3pp58ecsVl21mWZVdffXUu/uUvf9nmOWFPHHvssSE3efLkXDx//vxQ89xzz9XsTGCJNSkU+6xsmXBTU1PITZo0KRcfc8wxoebJJ58MubIeLp5h165dbdZQX8o+x5XdYxsaGnKxa6InJgAAAAAAgIQMJgAAAAAAgGQMJgAAAAAAgGQMJgAAAAAAgGTqcvl1cdHMpk2bQs0777wTcmULcT788MNcvH379nadwWIbUiv2/QsvvBBqhgwZEnIDBw4MufXr13/s76Zr6N27dy4uW3T9ox/9KORWrVoVco8//ngutuiaKpT12GuvvRZyBx10UC4uW/o5b968kHv66adDrnhf1+dQ38qWX5ctrC7eK5cvXx5qVqxYEXKPPPJIyN11111tngE+ieJ9McuybOvWrbn4hhtuCDUtLS01OxNAFcqWEJfdd4cNG9bmz5X9/aRM8Xrr2kqWWWzdXp6YAAAAAAAAkjGYAAAAAAAAkjGYAAAAAAAAkjGYAAAAAAAAkqnL5dfFBSNr164NNStXrgy55ubmkLO0hu6qrHeLy9yzzPL2rqihoSHk+vfvH3IXXHBBLp45c2aoKVtifckll4RcsTf0AF3FsmXLQu7KK6/MxV//+tdDTdk1sGypHUDZcsKXXnopF0+dOjXUPPTQQyF3/fXXh9z777//CU4HbXvttddCbvr06bn4ueeeS3UcgMqUfY8t+1vfAw88kItPOumkUNOrV/xvucu+XxeVfZ/3/RrKeWICAAAAAABIxmACAAAAAABIxmACAAAAAABIptvvmCizefPmXLx169ZQs2vXrlTHgS5D33cPvXv3DrmBAweG3Pjx43PxvvvuG2puvvnmkHviiSdCzrv36arKrlv33XdfLl6zZk2oefPNN0Ou7H2vAGWGDBmSi6+44opQs23btpBzP6UKCxcuDLni3ont27enOg5Al1L2fWLTpk25eMGCBaGm7Lo5YMCANn+Xv7tA+3liAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASMZgAgAAAAAASKYul18XWTwDdGW9euVnxPvtt1+oOfroo0PusMMOy8Wvv/56qJk9e3bIrV+/PuRaW1vbOiZ0GcUenjNnTqgp62mfB4AyvXv3DrnVq1fn4s2bN4ca9066irL7m3sewO5t2bIlF7/77ruhpk+f+CfTHTt2hJzrLXScJyYAAAAAAIBkDCYAAAAAAIBkDCYAAAAAAIBkDCYAAAAAAIBkesTya4CurLh0c/DgwaGmbOnm888/n4vnz58fat5+++2Q27lz554eEbo0PQ18EmXXkI0bN1ZwEgCgCu1dYF1W19ra2tnHgR7DExMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAydkwAVGzHjh25eOnSpaGmpaUl5GbPnp2L33nnnVDj3fsAAACwe2W7I7Zt2xZyDQ0NKY4DPYYnJgAAAAAAgGQMJgAAAAAAgGQMJgAAAAAAgGQMJgAAAAAAgGQsvwaoWGtray5u7+Ktpqamj/09WZZlvXrF+XNZHQAAALB7vktD5/LEBAAAAAAAkIzBBAAAAAAAkIzBBAAAAAAAkIzBBAAAAAAAkIzl1wBdTENDQ8h98MEHIdeexVtli7QBAACA3bPoGmrPExMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyBhMAAAAAAEAyll8DdDE7d+4MOUusAQAAAKgXnpgAAAAAAACSMZgAAAAAAACSMZgAAAAAAACSsWMCoBtobW2t+ggAUJcaGhpCzn0XACjymQE6lycmAAAAAACAZAwmAAAAAACAZAwmAAAAAACAZDq8Y8I71CiqdU/oOcroO1JL0RP6jiLXOqrQU/quq5wD91iq0VOudXQt+q576s7/f3WPpQpt9USHn5hobm7u6I9Sp2rdE3qOMvqO1FL0hL6jyLWOKug7UnOPpQqudVRB35GaeyxVaKsnGlo7OM7atWtX1tTUlDU2NpZupafnaG1tzZqbm7PRo0dnvXrV7u1geo7/pe9ILVXPZZm+479c66iCviM191iq4FpHFfQdqbnHUoX29l2HBxMAAAAAAAB7yvJrAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgGYMJAAAAAAAgmf8HHd89I3CtuwoAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}