{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# Add a Dense layer with a L1 activity regularizer\n",
    "encoded = layers.Dense(encoding_dim, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from credo import load_data\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = load_data(use_worms=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10912, 784)\n",
      "(496, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 1s 9ms/step - loss: 0.6046 - val_loss: 0.4189\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2534 - val_loss: 0.1518\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.1230 - val_loss: 0.1064\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0985 - val_loss: 0.0936\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0900 - val_loss: 0.0879\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0855 - val_loss: 0.0842\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0825 - val_loss: 0.0817\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0802 - val_loss: 0.0796\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0782 - val_loss: 0.0777\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0764 - val_loss: 0.0759\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.0742\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0710 - val_loss: 0.0706\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0693 - val_loss: 0.0689\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0675 - val_loss: 0.0672\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0658 - val_loss: 0.0654\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0641 - val_loss: 0.0637\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0624 - val_loss: 0.0620\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0607 - val_loss: 0.0604\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0591 - val_loss: 0.0588\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0575 - val_loss: 0.0572\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0560 - val_loss: 0.0557\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0545 - val_loss: 0.0542\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0531 - val_loss: 0.0528\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0518 - val_loss: 0.0515\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0505 - val_loss: 0.0503\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0493 - val_loss: 0.0491\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0483 - val_loss: 0.0480\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0473 - val_loss: 0.0470\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0463 - val_loss: 0.0461\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0455 - val_loss: 0.0453\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0447 - val_loss: 0.0445\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0439 - val_loss: 0.0438\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0433 - val_loss: 0.0431\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0426 - val_loss: 0.0425\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0420 - val_loss: 0.0419\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0415 - val_loss: 0.0414\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0409\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0405 - val_loss: 0.0404\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0401 - val_loss: 0.0400\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0397 - val_loss: 0.0395\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0393 - val_loss: 0.0392\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0389 - val_loss: 0.0388\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0385\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0378\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0376 - val_loss: 0.0375\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0373 - val_loss: 0.0373\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0370 - val_loss: 0.0370\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0368 - val_loss: 0.0368\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0365\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0358 - val_loss: 0.0359\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0356 - val_loss: 0.0357\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0354 - val_loss: 0.0355\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0352 - val_loss: 0.0353\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0350 - val_loss: 0.0351\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0348 - val_loss: 0.0349\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0347 - val_loss: 0.0347\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0346\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0343 - val_loss: 0.0344\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0341 - val_loss: 0.0342\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0340 - val_loss: 0.0341\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.0339\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0338\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0336\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0334 - val_loss: 0.0335\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0332 - val_loss: 0.0334\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0331 - val_loss: 0.0332\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0330 - val_loss: 0.0331\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0330\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.0329\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0326 - val_loss: 0.0327\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0325 - val_loss: 0.0326\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.0325\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0324\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0321 - val_loss: 0.0323\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0322\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0319 - val_loss: 0.0321\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0320\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0317 - val_loss: 0.0319\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.0318\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0317\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0314 - val_loss: 0.0316\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0313 - val_loss: 0.0315\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.0315\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.0314\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0313\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0309 - val_loss: 0.0312\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0309 - val_loss: 0.0312\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.0308 - val_loss: 0.0311\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0307 - val_loss: 0.0310\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0306 - val_loss: 0.0309\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0305 - val_loss: 0.0309\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0308\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0307\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.0307\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0302 - val_loss: 0.0306\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0302 - val_loss: 0.0306\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1652fc0ab30>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step\n",
      "16/16 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2000x400 with 20 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}